{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This function will change .pdb files to text files with a .entropy extension\n",
    "\n",
    "* runs through about **162 .pdb files** per minute\n",
    "* assumes directories that are inputted are already made\n",
    "* written using an explicit path that must be changed depending on computer\n",
    "* assumes `popcoen_server.py` is running (can only be run using python 2.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to run popcoen_server.py\n",
    "\n",
    "* install [Popcoen](http://fmc.ub.edu/popcoen/Popcoen_Full_Version1.tar.bz2)\n",
    "* open a **terminal** and **change directory** to `Popcoen_Full_Version1` directory\n",
    "* run `./popcoen_server.py` in a terminal\n",
    "\n",
    "\n",
    "IMPORTANT: _**This notebook must have a Python2 kernel in order to work since Popcoen was written in Python 2.x**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code assumes the popcoen_server.py script is running in a terminal\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "def pdb_to_text(pdb_dir,target_dir): #takes the current pdb_dir and where the outputted .txt files will be stored as arguments\n",
    "    \n",
    "    \"\"\"\n",
    "    Converts .pdb files from a specified directory within '/home/jupyter/tacc-work/Jan/pdb_files'\n",
    "    to text files with the extension .entropy in a specified directory within '/home/jupyter/\n",
    "    proteins.entropy'\n",
    "    \"\"\"\n",
    "    #make sure you are at the pdb_dir\n",
    "    path_name=''\n",
    "    if os.getcwd != '/home/jupyter/tacc-work/Jan/pdb_files':\n",
    "        os.chdir('/home/jupyter/tacc-work/Jan/pdb_files')\n",
    "    \n",
    "    #create path name\n",
    "    path_name = os.path.join(os.getcwd(),pdb_dir)\n",
    "    \n",
    "    print(\"path_name = \"+path_name)\n",
    "    os.chdir(path_name)\n",
    "    \n",
    "    #use glob to create a list of pdbs\n",
    "    pdb_list = glob('*.pdb')\n",
    "    \n",
    "    print('pdb list contains',len(pdb_list),'entries')\n",
    "    \n",
    "    #iterate through list\n",
    "    for protein in pdb_list: \n",
    "        #store the protein's name using os.path.basename and os.path.splitext[0]\n",
    "        name_tuple = os.path.splitext(protein)\n",
    "        name_protein = name_tuple[0] #not stored as a string\n",
    "        \n",
    "        #feed each term into Popcoen through command line using os.system // possible err is server not running\n",
    "        #grep through the output looking for \"Si-predict\", \"S_PC\", and \"Reliability-number\"\n",
    "        #store output in a text file <name>.entropy in the target_dir\n",
    "        os.system('/home/jupyter/tacc-work/maverick/Popcoen_Full_Version1/client_for_popcoen.py < '+ path_name+\"/\"+str(protein)+' | grep -e \\\"Si-predict:\\\" -e \\\"S_PC = sum Si =\\\" -e \\\"Reliability-number lambda =\\\">/home/jupyter/tacc-work/Jan/proteins.entropy/'+str(target_dir)+\"/\"+str(name_protein)+'.entropy')\n",
    "        \n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdb_to_text_v2(pdb_dir,target_dir, glob_list=True, list_of_pdb=None): #takes the current pdb_dir and where the outputted .txt files will be stored as arguments\n",
    "    \n",
    "    \"\"\"\n",
    "    Same as pdb_to_text but offers the option of manually feeding it a list of PDB files\n",
    "    \"\"\"\n",
    "    #make sure you are at the pdb_dir\n",
    "    original_path = os.getcwd()\n",
    "    if original_path != '/home/jupyter/tacc-work/Jan/PDB Files/':\n",
    "        os.chdir('/home/jupyter/tacc-work/Jan/PDB Files/')\n",
    "    \n",
    "    #create path name\n",
    "    path_name = os.path.join(os.getcwd(),pdb_dir)\n",
    "    \n",
    "    print(\"path_name = \"+path_name)\n",
    "    os.chdir(path_name)\n",
    "    \n",
    "    pdb_list = []\n",
    "    if glob_list:\n",
    "        #use glob to create a list of pdbs\n",
    "        pdb_list = glob('*.pdb')\n",
    "    else:\n",
    "        pdb_list = list_of_pdb\n",
    "    \n",
    "    print('pdb list contains',len(pdb_list),'entries')\n",
    "    \n",
    "    #iterate through list\n",
    "    for protein in pdb_list: \n",
    "        #store the protein's name using os.path.basename and os.path.splitext[0]\n",
    "        name_tuple = os.path.splitext(protein)\n",
    "        name_protein = name_tuple[0] #not stored as a string\n",
    "        \n",
    "        #feed each term into Popcoen through command line using os.system // possible err is server not running\n",
    "        #grep through the output looking for \"Si-predict\", \"S_PC\", and \"Reliability-number\"\n",
    "        #store output in a text file <name>.entropy in the target_dir\n",
    "        os.system('/home/jupyter/tacc-work/maverick/Popcoen_Full_Version1/client_for_popcoen.py < '+ path_name+\"/\"+str(protein)+' | grep -e \\\"Si-predict:\\\" -e \\\"S_PC = sum Si =\\\" -e \\\"Reliability-number lambda =\\\">/home/jupyter/tacc-work/Jan/proteins.entropy/'+str(target_dir)+\"/\"+str(name_protein)+'.entropy')\n",
    "    \n",
    "    #return to original path\n",
    "    os.chdir(original_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "topmin_df = pd.read_csv('/home/jupyter/tacc-work/Jan/topology_mining_untested_keys.csv')\n",
    "pdb_names = topmin_df['name_y'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_name = /home/jupyter/tacc-work/Jan/PDB Files/topology_mining_pdb\n",
      "('pdb list contains', 16720, 'entries')\n"
     ]
    }
   ],
   "source": [
    "pdb_to_text_v2('topology_mining_pdb', 'Topology_mining.entropy', glob_list=False,list_of_pdb=pdb_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ran the code on a test directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_name = /home/jupyter/tacc-work/Jan/PDB Files/Example\n",
      "('pdb list contains', 5, 'entries')\n"
     ]
    }
   ],
   "source": [
    "pdb_to_text_v2('Example','Example.entropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ran the code on `Eva1` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_name = /home/jupyter/Jan/pdb_files/Eva_data1\n"
     ]
    }
   ],
   "source": [
    "pdb_to_text('Eva_data1','Eva_data1.entropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ran the code on `Eva2` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_name = /home/jupyter/tacc-work/Jan/pdb_files/Eva_data2\n"
     ]
    }
   ],
   "source": [
    "pdb_to_text('Eva_data2','Eva_data2.entropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ran the code on `Inna` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_name = /home/jupyter/tacc-work/Jan/pdb_files/Inna_data\n"
     ]
    }
   ],
   "source": [
    "pdb_to_text('Inna_data','Inna_data.entropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ran the code on `Longxing` dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_name = /home/jupyter/tacc-work/Jan/pdb_files/Longxing_data\n"
     ]
    }
   ],
   "source": [
    "pdb_to_text('Longxing_data','Longxing_data.entropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ran the code on `Longxing_untested` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_name = /home/jupyter/tacc-work/Jan/pdb_files/Longxing_data_untested\n",
      "('pdb list contains', 63106, 'entries')\n"
     ]
    }
   ],
   "source": [
    "pdb_to_text('Longxing_data_untested','Longxing_data_untested.entropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ran the code on `Rocklin` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb_to_text('Rocklin_data','Rocklin_data.entropy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
